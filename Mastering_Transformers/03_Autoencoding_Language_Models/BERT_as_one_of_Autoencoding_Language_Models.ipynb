{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CH03a_BERT_As_one_of_Autoencoding_Language_Models.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5661f9afceac41cd81911ec61f840d1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0fe97a5a63614b35b1a58cb8d9765242",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6295bed1bbfc43ff8bd374152775b094",
              "IPY_MODEL_91e3626b49814c7e85fc351d6cea403c"
            ]
          }
        },
        "0fe97a5a63614b35b1a58cb8d9765242": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6295bed1bbfc43ff8bd374152775b094": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cd7b13f0ba0f44a88b1d085fb5acf789",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_24e111b1fc5746a8a69f862a0dc3bc7d"
          }
        },
        "91e3626b49814c7e85fc351d6cea403c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e345fb951df24e0d848a051a485b4b65",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:01&lt;00:00, 327B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_86b7927b6dc44fb28cf3b006163c39cf"
          }
        },
        "cd7b13f0ba0f44a88b1d085fb5acf789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "24e111b1fc5746a8a69f862a0dc3bc7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e345fb951df24e0d848a051a485b4b65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "86b7927b6dc44fb28cf3b006163c39cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "133035cbbade4827bc6764218387a54b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e4efd2d54399463db446591d18cbe6fd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c1e03b6d025a4dba9e37eb35c48d93ec",
              "IPY_MODEL_62399066111345ec827e1912ec1d97ba"
            ]
          }
        },
        "e4efd2d54399463db446591d18cbe6fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c1e03b6d025a4dba9e37eb35c48d93ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_73ca0820cf8a482bb3cb4bd658e7a5d3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 536063208,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 536063208,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2989c05594ea4054b311517ce5339ed2"
          }
        },
        "62399066111345ec827e1912ec1d97ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ef71247bb53a4c709d59e63ab7d60c33",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 536M/536M [00:30&lt;00:00, 17.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_62b92d97fdcb49b1ade6d076d0b203eb"
          }
        },
        "73ca0820cf8a482bb3cb4bd658e7a5d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2989c05594ea4054b311517ce5339ed2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef71247bb53a4c709d59e63ab7d60c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "62b92d97fdcb49b1ade6d076d0b203eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "94a9c2fcf79f4ac0a8f2d712411f7d2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d8e8c28122024aadb70ff1aab5530eeb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7a9083129f274149a176a0e31eb48411",
              "IPY_MODEL_dac236c954ef4b0f99067b8bbeba6283"
            ]
          }
        },
        "d8e8c28122024aadb70ff1aab5530eeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a9083129f274149a176a0e31eb48411": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_96ad3e5ee6bc4398a0c6e8ea948682a4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3f2e7ff1d0ad466196075aad10b8b84a"
          }
        },
        "dac236c954ef4b0f99067b8bbeba6283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9fb9172e15b3405fab9a7db14d0c560d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 798kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_48f55d9d4e3046d5abe21fef5b2a377c"
          }
        },
        "96ad3e5ee6bc4398a0c6e8ea948682a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3f2e7ff1d0ad466196075aad10b8b84a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9fb9172e15b3405fab9a7db14d0c560d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "48f55d9d4e3046d5abe21fef5b2a377c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d102900f8884e44aa4953d89ad79465": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6946d2105b2e4fd1bfab2b10f1256053",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0b351be38ce9450eb4f4a857132b0a79",
              "IPY_MODEL_c41a59274c78422fa1c846a1711b2439"
            ]
          }
        },
        "6946d2105b2e4fd1bfab2b10f1256053": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b351be38ce9450eb4f4a857132b0a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_477900896cec431f98ed705f5fbbf78b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6cead6beda334e7a8db3f27ad5845705"
          }
        },
        "c41a59274c78422fa1c846a1711b2439": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d26b4d4dbcd243cd8933f81fffad0b4d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 2.94MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a0d2c4f1560a4a6bab0be1285c932283"
          }
        },
        "477900896cec431f98ed705f5fbbf78b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6cead6beda334e7a8db3f27ad5845705": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d26b4d4dbcd243cd8933f81fffad0b4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a0d2c4f1560a4a6bab0be1285c932283": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9dac89e1bf484a1fafaa1b5235846d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2290a421c99944a19da4fa1888204a0a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3fe4f71880a5497e950d15a381614651",
              "IPY_MODEL_7fc1dee184a54de987dbba3af55c597e"
            ]
          }
        },
        "2290a421c99944a19da4fa1888204a0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3fe4f71880a5497e950d15a381614651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4e9a142be38247088fe4f3a7d6ecd6f3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_127e05f39b2d4b0f84dd7ca57d71cc98"
          }
        },
        "7fc1dee184a54de987dbba3af55c597e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_73de1777b2f5478891fc9b8dc46c26a0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:08&lt;00:00, 3.33B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_476bdde5624144919c7abb27938c7221"
          }
        },
        "4e9a142be38247088fe4f3a7d6ecd6f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "127e05f39b2d4b0f84dd7ca57d71cc98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "73de1777b2f5478891fc9b8dc46c26a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "476bdde5624144919c7abb27938c7221": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sihan-A/HuggingFace/blob/main/Mastering_Transformers/03_Autoencoding_Language_Models/BERT_as_one_of_Autoencoding_Language_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v61w8HXuZrLH"
      },
      "source": [
        "# BERT: As one of Autoencoding Language Models "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYz04Dinzk0M",
        "outputId": "17afb7d0-6e5b-4fdf-eb83-238fedd6fc92"
      },
      "source": [
        "!gdown --id 1P4FInZUkD1LDN4SIIOLLBYk_ALmCDBG2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1P4FInZUkD1LDN4SIIOLLBYk_ALmCDBG2\n",
            "To: /content/IMDB_Dataset.zip\n",
            "100% 26.6M/26.6M [00:00<00:00, 64.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3bcOfnNWJhv",
        "outputId": "e3818d4a-f6a0-4e71-8185-522e26dba545"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 51.5 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 79.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 73.2 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.19 pyyaml-5.4.1 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDuHvNUnbRXu",
        "outputId": "65c78b86-048b-43ec-cb9c-dada9f3114f0"
      },
      "source": [
        "!pip install tokenizers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.10.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGJiQ2Sx4mm7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b1b44f9-c32b-4445-f3a9-cf404d009cdb"
      },
      "source": [
        "!unzip /content/IMDB_Dataset.zip "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/IMDB_Dataset.zip\n",
            "  inflating: IMDB_Dataset.csv        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJbh3P-e3g0S"
      },
      "source": [
        "import pandas as pd\n",
        "imdb_df = pd.read_csv(\"IMDB_Dataset.csv\")\n",
        "reviews = imdb_df.review.to_string(index=None) \n",
        "with open(\"corpus.txt\", \"w\") as f: \n",
        "    f.writelines(reviews) "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQRzoQKS4SA2"
      },
      "source": [
        "from tokenizers import BertWordPieceTokenizer\n",
        "bert_wordpiece_tokenizer = BertWordPieceTokenizer() \n",
        "bert_wordpiece_tokenizer.train(\"corpus.txt\") "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "datICiehV7kv",
        "outputId": "82a48d03-35f6-496f-f4c3-73f5e916639e"
      },
      "source": [
        "bert_wordpiece_tokenizer.get_vocab()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'doesn': 1143,\n",
              " 'outf': 14954,\n",
              " '##isio': 14402,\n",
              " 'returning': 13461,\n",
              " 'alter': 7296,\n",
              " 'lege': 12130,\n",
              " 'aaliyah': 18051,\n",
              " '##ju': 7896,\n",
              " 'undisputed': 17636,\n",
              " 'barrel': 10471,\n",
              " '##l': 100,\n",
              " 'slam': 5578,\n",
              " 'sense': 2196,\n",
              " 'understa': 10869,\n",
              " 'elton': 15673,\n",
              " 'moves': 4690,\n",
              " 'profanity': 16353,\n",
              " 'infamous': 3998,\n",
              " 'hooper': 5707,\n",
              " 'ingredients': 7738,\n",
              " '##aa': 2492,\n",
              " 'craft': 15491,\n",
              " 'jack': 1034,\n",
              " 'viole': 13489,\n",
              " 'severe': 15767,\n",
              " 'flic': 7377,\n",
              " 'candidate': 13727,\n",
              " 'fascist': 10728,\n",
              " 'career': 2507,\n",
              " 'shrieker': 17407,\n",
              " 'lesser': 4788,\n",
              " 'fam': 660,\n",
              " 'walker': 6384,\n",
              " '##iance': 6313,\n",
              " 'vehicle': 3640,\n",
              " '##sp': 940,\n",
              " '##ello': 5028,\n",
              " 'lupin': 12407,\n",
              " 'kare': 14007,\n",
              " 'unrelent': 11318,\n",
              " 'began': 2612,\n",
              " 'earned': 10423,\n",
              " '##mber': 5199,\n",
              " 'shimizu': 18164,\n",
              " 'points': 3157,\n",
              " 'did': 417,\n",
              " 'albuquerque': 18296,\n",
              " 'garson': 12656,\n",
              " '##arno': 14473,\n",
              " '##onge': 14494,\n",
              " 'hassel': 14863,\n",
              " 'picks': 10601,\n",
              " 'deli': 2030,\n",
              " '##gro': 9936,\n",
              " 'harmless': 11198,\n",
              " 'strummer': 15431,\n",
              " 'redeemed': 16494,\n",
              " '##stige': 17724,\n",
              " 'towns': 16086,\n",
              " '##ilar': 1063,\n",
              " 'columb': 2183,\n",
              " 'nak': 9814,\n",
              " '##mination': 17191,\n",
              " 'kath': 4139,\n",
              " 'bela': 3397,\n",
              " 'taiwan': 11291,\n",
              " 'lux': 9111,\n",
              " '##bled': 5187,\n",
              " 'koontz': 9695,\n",
              " 'problems': 3011,\n",
              " 'errone': 10871,\n",
              " 'spok': 7990,\n",
              " 'pants': 8698,\n",
              " 'meticulously': 17854,\n",
              " 'directin': 15106,\n",
              " 'depicts': 10956,\n",
              " 'nost': 14979,\n",
              " 'underst': 3149,\n",
              " '##orthy': 5377,\n",
              " '##olas': 3584,\n",
              " 'mic': 3883,\n",
              " 'limon': 14699,\n",
              " 'ones': 4696,\n",
              " '##table': 4319,\n",
              " 'arth': 12141,\n",
              " '1982': 4390,\n",
              " 'indie': 3328,\n",
              " 'latcho': 16287,\n",
              " 'abysmally': 17046,\n",
              " '##lesc': 15506,\n",
              " 'eighty': 16464,\n",
              " 'kicks': 8365,\n",
              " '##aim': 1795,\n",
              " '##iart': 14248,\n",
              " '##72': 11668,\n",
              " 'centur': 10702,\n",
              " 'gad': 5757,\n",
              " 'horri': 8050,\n",
              " '#': 7,\n",
              " '##zot': 14374,\n",
              " 'empty': 7079,\n",
              " '##thur': 2982,\n",
              " 'summ': 1136,\n",
              " '##azine': 5002,\n",
              " 'prote': 8885,\n",
              " 'pro': 407,\n",
              " 'spirit': 3017,\n",
              " 'reiser': 10015,\n",
              " 'entertaini': 10496,\n",
              " 'brat': 11823,\n",
              " 'fishbourne': 17180,\n",
              " 'frat': 14717,\n",
              " 'enj': 453,\n",
              " 'colleges': 12562,\n",
              " 'daph': 11387,\n",
              " '##´s': 3455,\n",
              " 'snl': 7504,\n",
              " 'serves': 10292,\n",
              " 'domer': 16747,\n",
              " 'plight': 10182,\n",
              " 'jenn': 3352,\n",
              " 'indulgent': 6537,\n",
              " 'fed': 5148,\n",
              " 'whodun': 7095,\n",
              " 'medium': 16253,\n",
              " 'lackl': 9303,\n",
              " 'deemed': 17912,\n",
              " '##enda': 8990,\n",
              " '##ashbuck': 10460,\n",
              " 'harlin': 15656,\n",
              " 'guys': 1701,\n",
              " 'preach': 6761,\n",
              " 'futuristic': 11268,\n",
              " 'reall': 3463,\n",
              " 'electric': 13322,\n",
              " 'inap': 11741,\n",
              " 'holy': 4556,\n",
              " 'exposed': 8245,\n",
              " 'ohdear': 12333,\n",
              " 'dual': 11382,\n",
              " 'tep': 15104,\n",
              " 'bett': 4062,\n",
              " 'caught': 1162,\n",
              " 'bundled': 16119,\n",
              " 'mingh': 9631,\n",
              " 'ontario': 17885,\n",
              " '##vering': 11821,\n",
              " 'where': 580,\n",
              " 'warm': 4546,\n",
              " 'power': 1484,\n",
              " 'cynthia': 13182,\n",
              " 'shopping': 10905,\n",
              " '##itter': 6226,\n",
              " 'sometimes': 1600,\n",
              " 'darkness': 2872,\n",
              " '##emy': 3050,\n",
              " 'suave': 14805,\n",
              " 'wip': 14164,\n",
              " 'deceiving': 17021,\n",
              " 'preparing': 17153,\n",
              " 'widesc': 18136,\n",
              " 'benedict': 16482,\n",
              " 'loess': 11898,\n",
              " '##lect': 4165,\n",
              " 'audiard': 13513,\n",
              " '##amin': 11837,\n",
              " 'babies': 16202,\n",
              " 'plough': 14936,\n",
              " 'swan': 9176,\n",
              " '##bian': 3896,\n",
              " 'policeman': 12539,\n",
              " 'frances': 9267,\n",
              " 'bul': 4452,\n",
              " 'recentl': 16329,\n",
              " 'chamberlain': 11336,\n",
              " 'hailed': 7256,\n",
              " 'physics': 10992,\n",
              " 'sentinel': 8318,\n",
              " 'rapp': 10939,\n",
              " 'burt': 3168,\n",
              " 'interes': 6385,\n",
              " '##ing': 152,\n",
              " 'tamo': 17038,\n",
              " 'mostly': 2342,\n",
              " 'ouch': 8320,\n",
              " '##ala': 11736,\n",
              " '##zna': 9945,\n",
              " 'chief': 10099,\n",
              " '##igo': 7344,\n",
              " 'mcadam': 12796,\n",
              " 'industrial': 13722,\n",
              " '##ifi': 3067,\n",
              " '##mmm': 12339,\n",
              " '##clear': 7603,\n",
              " '##apo': 6754,\n",
              " 'wrath': 12118,\n",
              " 'transported': 17590,\n",
              " '##los': 14270,\n",
              " '##sula': 14198,\n",
              " 'up': 405,\n",
              " 'meanings': 15745,\n",
              " 'hane': 8665,\n",
              " '##fy': 9928,\n",
              " 'digest': 11986,\n",
              " 'i´': 6604,\n",
              " 'birthday': 4849,\n",
              " 'players': 10440,\n",
              " 'tutor': 13487,\n",
              " 'jew': 3653,\n",
              " 'inform': 3989,\n",
              " 'hauer': 13594,\n",
              " '##orse': 11693,\n",
              " 'stink': 2339,\n",
              " 'hobb': 12337,\n",
              " '##ad': 179,\n",
              " 'dig': 3687,\n",
              " 'mcdo': 16294,\n",
              " '##ionage': 11854,\n",
              " 'footlight': 10757,\n",
              " 'delete': 17540,\n",
              " '##aine': 3927,\n",
              " 'acade': 10377,\n",
              " 'cry': 2376,\n",
              " 'versatile': 15510,\n",
              " 'ally': 11913,\n",
              " '##ashi': 5940,\n",
              " 'misgu': 12380,\n",
              " 'flamenco': 15229,\n",
              " 'kristofferson': 11271,\n",
              " 'experimenting': 13162,\n",
              " 'product': 3000,\n",
              " 'sized': 14117,\n",
              " '<': 32,\n",
              " 'wils': 16422,\n",
              " 'tiger': 8535,\n",
              " 'unappe': 15040,\n",
              " '##ank': 954,\n",
              " 'describes': 5088,\n",
              " 'clueless': 13240,\n",
              " 'christophe': 15708,\n",
              " 'scheider': 17772,\n",
              " 'awe': 5555,\n",
              " 'theatric': 15734,\n",
              " 'far': 638,\n",
              " 'self': 2235,\n",
              " 'thought': 480,\n",
              " 'jus': 3752,\n",
              " '20': 1459,\n",
              " 'waqt': 12255,\n",
              " 'trade': 14967,\n",
              " 'harlow': 10510,\n",
              " 'add': 1411,\n",
              " 'y': 67,\n",
              " 'convenientl': 18206,\n",
              " 'superl': 12496,\n",
              " '##ions': 1826,\n",
              " 'marketing': 13132,\n",
              " 'indep': 1989,\n",
              " 'drum': 5903,\n",
              " 'parad': 8170,\n",
              " 'beckinsale': 11275,\n",
              " '##time': 2566,\n",
              " 'resound': 16051,\n",
              " 'minus': 7400,\n",
              " 'press': 4353,\n",
              " 'judged': 10732,\n",
              " 'franch': 4585,\n",
              " 'mummy': 5532,\n",
              " 'purpose': 7021,\n",
              " 'footprints': 9720,\n",
              " 'pleasingly': 15631,\n",
              " 'fata': 8353,\n",
              " 'washing': 5224,\n",
              " 'rio': 9833,\n",
              " 'sorrow': 15819,\n",
              " 'toilet': 8577,\n",
              " 'wet': 6634,\n",
              " 'intentionally': 10909,\n",
              " 'bou': 13872,\n",
              " 'hulce': 17115,\n",
              " 'marriage': 7749,\n",
              " 'outside': 4615,\n",
              " 'undoubt': 3186,\n",
              " 'hands': 2548,\n",
              " 'rebane': 17327,\n",
              " 'keeper': 17421,\n",
              " 'harem': 15654,\n",
              " 'subgen': 15695,\n",
              " 'sha': 5841,\n",
              " 'closely': 7582,\n",
              " 'lauded': 12393,\n",
              " 'mannen': 17050,\n",
              " '##anners': 12904,\n",
              " '##ield': 2367,\n",
              " 'andress': 14566,\n",
              " '##rack': 10143,\n",
              " '##ough': 339,\n",
              " '##ments': 2624,\n",
              " 'seasoning': 16139,\n",
              " 'category': 5107,\n",
              " 'inept': 6060,\n",
              " 'ronnie': 16678,\n",
              " 'gru': 10330,\n",
              " 'c': 45,\n",
              " 'legged': 15141,\n",
              " 'olivia': 17173,\n",
              " 'clothing': 15069,\n",
              " 'olym': 14066,\n",
              " 'apocal': 16927,\n",
              " '##ien': 561,\n",
              " 'miscast': 8146,\n",
              " 'unaware': 11317,\n",
              " '##uck': 1300,\n",
              " 'shed': 10063,\n",
              " 'administr': 18238,\n",
              " 'motor': 12958,\n",
              " 'match': 5950,\n",
              " 'linear': 10899,\n",
              " '##erella': 3682,\n",
              " 'kriem': 16547,\n",
              " 'isle': 14458,\n",
              " 'seven': 2457,\n",
              " '##ining': 11677,\n",
              " 'badly': 2540,\n",
              " 'suffice': 16603,\n",
              " '##head': 1888,\n",
              " 'we': 238,\n",
              " 'spoon': 14841,\n",
              " 'enthrall': 10906,\n",
              " 'thanksgiving': 16872,\n",
              " 'misn': 12379,\n",
              " 'bloch': 10316,\n",
              " 'epic': 2628,\n",
              " '##crack': 11012,\n",
              " 'breaking': 5056,\n",
              " 'navy': 6116,\n",
              " 'collectio': 17131,\n",
              " '##aste': 2989,\n",
              " 'meet': 3471,\n",
              " 'major': 1621,\n",
              " 'condie': 14988,\n",
              " 'alison': 14818,\n",
              " '##x': 113,\n",
              " '##endous': 3141,\n",
              " 'mohan': 14447,\n",
              " 'thhe': 14393,\n",
              " 'misunderst': 7750,\n",
              " '1943': 7537,\n",
              " 'gid': 13947,\n",
              " '##sca': 15717,\n",
              " 'awk': 4982,\n",
              " '##atin': 11686,\n",
              " '##riers': 14771,\n",
              " '##kimo': 11610,\n",
              " 'contemporary': 9601,\n",
              " 'kid': 783,\n",
              " 'shoul': 7266,\n",
              " 'vind': 14145,\n",
              " 'burton': 3838,\n",
              " 'implaus': 11018,\n",
              " 'aimed': 7009,\n",
              " 'unjustly': 13798,\n",
              " 'tark': 14124,\n",
              " 'fantasies': 16344,\n",
              " 'inspir': 4599,\n",
              " 'cringing': 17203,\n",
              " 'tib': 11517,\n",
              " 'stilted': 6525,\n",
              " 'kans': 7816,\n",
              " 'alway': 10417,\n",
              " 'melo': 16047,\n",
              " 'delivers': 3517,\n",
              " 'brains': 16470,\n",
              " 'hip': 4367,\n",
              " 'ome': 11477,\n",
              " 'ob': 884,\n",
              " 'quality': 1914,\n",
              " 'uncut': 8441,\n",
              " 'tapes': 13068,\n",
              " 'crafted': 4124,\n",
              " 'feat': 942,\n",
              " '##uls': 7972,\n",
              " 'johnny': 3490,\n",
              " '##iable': 9895,\n",
              " 'geared': 17842,\n",
              " 'archie': 13128,\n",
              " 'modeling': 13074,\n",
              " 'brows': 6247,\n",
              " 'didn': 647,\n",
              " 'reflection': 10715,\n",
              " 'laun': 9203,\n",
              " 'thrille': 12180,\n",
              " 'gadar': 17271,\n",
              " '##imate': 6727,\n",
              " 'bir': 2890,\n",
              " '##line': 1526,\n",
              " 'model': 3339,\n",
              " '##rell': 7930,\n",
              " 'forgive': 9373,\n",
              " 'cur': 1183,\n",
              " 'prix': 16157,\n",
              " 'richards': 16177,\n",
              " 'counted': 13263,\n",
              " 'supporting': 12494,\n",
              " 'loca': 10606,\n",
              " 'slice': 6327,\n",
              " 'wartime': 11294,\n",
              " 'elected': 16057,\n",
              " 'cul': 8635,\n",
              " 'akshay': 17443,\n",
              " 'prec': 5871,\n",
              " 'racketeer': 13338,\n",
              " 'swinging': 17784,\n",
              " '##ll': 184,\n",
              " 'festivals': 13269,\n",
              " 'learns': 16396,\n",
              " 'prone': 11916,\n",
              " 'sting': 14589,\n",
              " '##roy': 14223,\n",
              " '##hart': 14368,\n",
              " 'drops': 15349,\n",
              " 'infer': 6923,\n",
              " 'valid': 16071,\n",
              " '##ese': 1228,\n",
              " 'quot': 7357,\n",
              " 'parade': 8172,\n",
              " 'gave': 1156,\n",
              " 'tonto': 14131,\n",
              " '##omwell': 11751,\n",
              " '##lyn': 5820,\n",
              " 'watching': 425,\n",
              " 'rolling': 8073,\n",
              " 'mame': 11457,\n",
              " 'potem': 9213,\n",
              " 'tales': 3949,\n",
              " '84': 13859,\n",
              " 'galaxy': 9652,\n",
              " 'conscience': 15590,\n",
              " 'scrip': 14928,\n",
              " 'sucker': 5050,\n",
              " 'yo': 1761,\n",
              " 'africa': 5679,\n",
              " 'hef': 15097,\n",
              " 'dolph': 4885,\n",
              " 'pleasantly': 4828,\n",
              " 'fantastical': 17164,\n",
              " 'glimps': 17350,\n",
              " 'transl': 6055,\n",
              " 'rhy': 13287,\n",
              " 'mouth': 7221,\n",
              " 'vcr': 14154,\n",
              " 'expl': 1235,\n",
              " 'copy': 2133,\n",
              " 'twists': 5263,\n",
              " '##men': 1856,\n",
              " 'insipid': 5731,\n",
              " '##umar': 8052,\n",
              " 'niel': 8692,\n",
              " 'playboy': 12324,\n",
              " 'translation': 13401,\n",
              " '##pp': 353,\n",
              " 'sat': 923,\n",
              " 'ey': 1290,\n",
              " 'alex': 2436,\n",
              " 'christopher': 2873,\n",
              " 'finding': 4560,\n",
              " 'ire': 5448,\n",
              " 'psychic': 12828,\n",
              " 'varney': 16204,\n",
              " 'levres': 15143,\n",
              " '##ely': 466,\n",
              " 'election': 10660,\n",
              " 'trappings': 15394,\n",
              " '##ifting': 8137,\n",
              " 'almighty': 5298,\n",
              " 'sellin': 16760,\n",
              " 'dat': 11378,\n",
              " 'enthusiastic': 9524,\n",
              " 'history': 1646,\n",
              " 'angela': 8315,\n",
              " '!': 5,\n",
              " 'rep': 1439,\n",
              " 'pix': 5170,\n",
              " 'logic': 6738,\n",
              " '##uri': 5510,\n",
              " 'suite': 14804,\n",
              " 'chess': 7282,\n",
              " 'charm': 6319,\n",
              " 'stallone': 9636,\n",
              " 'gla': 9138,\n",
              " 'spooky': 8504,\n",
              " 'dougl': 3820,\n",
              " 'exercise': 4866,\n",
              " 'hamilto': 17364,\n",
              " 'marg': 7426,\n",
              " 'ust': 7852,\n",
              " 'inki': 14525,\n",
              " 'pokemon': 5422,\n",
              " 'shif': 14685,\n",
              " 'shaw': 5845,\n",
              " 'jump': 4465,\n",
              " '##ffect': 11638,\n",
              " 'mcl': 8296,\n",
              " 'gods': 8177,\n",
              " 'pregn': 15008,\n",
              " 'dude': 5147,\n",
              " 'abra': 11857,\n",
              " 'queer': 12090,\n",
              " 'substand': 15694,\n",
              " 'contain': 970,\n",
              " '##enosets': 13659,\n",
              " 'apo': 3747,\n",
              " 'dizzy': 14922,\n",
              " 'eld': 13917,\n",
              " 'views': 7435,\n",
              " 'pra': 2465,\n",
              " 'girlf': 2350,\n",
              " 'railway': 10621,\n",
              " 'mixed': 3730,\n",
              " 'macb': 7628,\n",
              " '##umble': 5260,\n",
              " 'sarcastic': 10782,\n",
              " 'emeril': 17482,\n",
              " '##ther': 1686,\n",
              " 'guts': 5400,\n",
              " '##point': 9048,\n",
              " 'solar': 12756,\n",
              " 'eye': 2282,\n",
              " 'lloyd': 5945,\n",
              " 'suff': 2620,\n",
              " 'michel': 12491,\n",
              " '##gered': 16097,\n",
              " 'web': 6262,\n",
              " 'supply': 15735,\n",
              " 'nu': 3657,\n",
              " 'sen': 4150,\n",
              " 'starte': 15129,\n",
              " 'midway': 15808,\n",
              " 'worl': 7292,\n",
              " 'lied': 14026,\n",
              " 'deceptively': 13495,\n",
              " 'restored': 12931,\n",
              " 'raving': 15958,\n",
              " 'saps': 11877,\n",
              " '##iou': 11580,\n",
              " '##adh': 14578,\n",
              " 'minutes': 1073,\n",
              " '##8': 124,\n",
              " '1957': 6868,\n",
              " 'showed': 2991,\n",
              " 'recognition': 13181,\n",
              " 'vampir': 12789,\n",
              " '##istible': 14951,\n",
              " 'owner': 7535,\n",
              " '##pit': 14346,\n",
              " 'bac': 4006,\n",
              " 'fou': 5754,\n",
              " 'youssef': 13782,\n",
              " 'presc': 15006,\n",
              " 'whodunn': 17441,\n",
              " 'buon': 15452,\n",
              " 'pickford': 7514,\n",
              " 'flyer': 16675,\n",
              " 'spheeris': 11307,\n",
              " 'exploitation': 4227,\n",
              " 'ignor': 6982,\n",
              " '##ving': 452,\n",
              " 'produces': 10421,\n",
              " 'perfection': 8506,\n",
              " 'relationship': 4276,\n",
              " 'sty': 1720,\n",
              " 'buscemi': 16463,\n",
              " 'buyer': 16626,\n",
              " 'piv': 14081,\n",
              " 'growing': 3143,\n",
              " 'bronenosets': 16998,\n",
              " '##kow': 14287,\n",
              " 'dese': 10343,\n",
              " 'beat': 2495,\n",
              " 'quo': 10269,\n",
              " 'decides': 6355,\n",
              " 'act': 290,\n",
              " 'orph': 8071,\n",
              " 'id': 1532,\n",
              " 'role': 1925,\n",
              " 'margher': 10435,\n",
              " '##cal': 11597,\n",
              " 'transform': 13007,\n",
              " 'host': 4305,\n",
              " 'kenn': 5768,\n",
              " 'taut': 11516,\n",
              " '##ilight': 4935,\n",
              " '19th': 8928,\n",
              " 'their': 1215,\n",
              " '##rific': 1990,\n",
              " 'kinds': 5295,\n",
              " 'ultimatum': 9396,\n",
              " 'millionaire': 13247,\n",
              " 'gig': 7809,\n",
              " 'poke': 4519,\n",
              " 'adam': 2795,\n",
              " '##manuelle': 13804,\n",
              " '##urn': 818,\n",
              " 'rebirth': 17328,\n",
              " 'captivating': 9597,\n",
              " 'children': 1930,\n",
              " '##eba': 11578,\n",
              " 'millions': 6019,\n",
              " '##asure': 3457,\n",
              " '##bind': 6642,\n",
              " 'empt': 6362,\n",
              " 'try': 1639,\n",
              " 'chock': 8873,\n",
              " 'white': 1823,\n",
              " 'wak': 14161,\n",
              " 'serge': 5547,\n",
              " 'hoot': 5016,\n",
              " '##nyard': 15258,\n",
              " '##opher': 2749,\n",
              " 'pastor': 16297,\n",
              " 'uninterest': 6499,\n",
              " '##vies': 4495,\n",
              " 'wou': 5180,\n",
              " 'azumi': 11350,\n",
              " 'dramas': 6043,\n",
              " 'hei': 12095,\n",
              " 'misnomer': 17955,\n",
              " 'salt': 10830,\n",
              " 'an': 156,\n",
              " '##plic': 8117,\n",
              " 'audacious': 16129,\n",
              " 'lorna': 13063,\n",
              " 'adjective': 13685,\n",
              " 'cab': 3268,\n",
              " 'rid': 1387,\n",
              " 'cutest': 12579,\n",
              " '##sembled': 9383,\n",
              " 'having': 685,\n",
              " 'sydne': 17134,\n",
              " 'velvet': 5134,\n",
              " 'witchy': 16847,\n",
              " 'suf': 14803,\n",
              " 'kirsten': 18035,\n",
              " 'gor': 6598,\n",
              " 'dramedy': 18232,\n",
              " '##ashed': 15550,\n",
              " 'wisecracking': 18029,\n",
              " 'carla': 6023,\n",
              " 'amateur': 3532,\n",
              " '##ess': 399,\n",
              " 'timberlake': 11312,\n",
              " 'gayniggers': 13835,\n",
              " 'hours': 2032,\n",
              " 'hints': 13973,\n",
              " 'chicago': 3993,\n",
              " 'sordid': 18120,\n",
              " 'purple': 4413,\n",
              " 'retire': 12535,\n",
              " 'treason': 15879,\n",
              " 'problem': 1357,\n",
              " 'create': 4570,\n",
              " '##aughter': 2219,\n",
              " 'club': 3137,\n",
              " 'ken': 3546,\n",
              " 'crime': 2072,\n",
              " '##or': 142,\n",
              " 'filmed': 1997,\n",
              " '##nig': 11575,\n",
              " 'tec': 12103,\n",
              " 'spoil': 416,\n",
              " '##pir': 5203,\n",
              " 'branagh': 4951,\n",
              " 'fees': 15010,\n",
              " '##itko': 9992,\n",
              " '##enching': 15855,\n",
              " '##eer': 4483,\n",
              " 'wesley': 5680,\n",
              " 'throug': 6069,\n",
              " 'angst': 8242,\n",
              " 'memorab': 16367,\n",
              " 'sleepers': 16879,\n",
              " 'undone': 12220,\n",
              " 'haz': 7254,\n",
              " '##ishment': 8062,\n",
              " 'kudos': 7767,\n",
              " 'jun': 5156,\n",
              " 'german': 1932,\n",
              " 'owes': 5690,\n",
              " 'tras': 10196,\n",
              " 'hugh': 5290,\n",
              " 'freleng': 9221,\n",
              " 'packing': 16578,\n",
              " 'languid': 16926,\n",
              " 'minut': 906,\n",
              " 'shocking': 4805,\n",
              " 'relentlessly': 17781,\n",
              " 'emotionally': 5657,\n",
              " '##orgino': 11698,\n",
              " 'performed': 9158,\n",
              " '##da': 4673,\n",
              " 'nomad': 11153,\n",
              " '##tra': 2836,\n",
              " 'chin': 2980,\n",
              " 'gol': 7808,\n",
              " '##tar': 9896,\n",
              " '##avian': 15522,\n",
              " 'undead': 15286,\n",
              " 'clear': 1562,\n",
              " 'dancing': 4402,\n",
              " 'hey': 2239,\n",
              " 'longer': 5919,\n",
              " 'dorm': 13104,\n",
              " 'downtown': 10490,\n",
              " 'acts': 10163,\n",
              " 'nichols': 11145,\n",
              " 'lamest': 6924,\n",
              " 'bigfoot': 8619,\n",
              " 'biggest': 1802,\n",
              " 'trains': 9041,\n",
              " 'mutant': 17316,\n",
              " 'sunday': 4091,\n",
              " 'bender': 9750,\n",
              " 'luxury': 11250,\n",
              " 'partial': 15399,\n",
              " 'slum': 9023,\n",
              " 'monica': 15594,\n",
              " 'robson': 16168,\n",
              " 'courtes': 16228,\n",
              " 'sica': 11504,\n",
              " 'starring': 1541,\n",
              " 'restrictions': 17886,\n",
              " 'kaufman': 13645,\n",
              " 'dogma': 16232,\n",
              " 'lear': 2110,\n",
              " 'bbc1': 16531,\n",
              " 'seventy': 17045,\n",
              " 'chipmunk': 13675,\n",
              " 'hardy': 3489,\n",
              " 'tenant': 9192,\n",
              " '##aglen': 10322,\n",
              " 'tell': 918,\n",
              " 'ima': 15122,\n",
              " 'alth': 682,\n",
              " 'relevance': 17044,\n",
              " 'roger': 3484,\n",
              " 'head': 1668,\n",
              " 'hend': 8663,\n",
              " 'beco': 10286,\n",
              " '1944': 7538,\n",
              " 'cleverly': 7583,\n",
              " 'mississippi': 11328,\n",
              " '##aling': 3202,\n",
              " 'straub': 15981,\n",
              " '##iko': 6653,\n",
              " 'chic': 3376,\n",
              " 'jazzy': 13754,\n",
              " 'golde': 16078,\n",
              " 'puzzled': 17360,\n",
              " 'insult': 3413,\n",
              " 'feelgood': 12390,\n",
              " 'prue': 14820,\n",
              " 'superhero': 6858,\n",
              " 'intelligent': 2600,\n",
              " '##ativ': 14422,\n",
              " 'thats': 4335,\n",
              " 'joseph': 4857,\n",
              " 'thieves': 11230,\n",
              " 'replaces': 17725,\n",
              " 'episodic': 12327,\n",
              " 'cautious': 17221,\n",
              " 'gugino': 12233,\n",
              " 'scare': 3474,\n",
              " 'uns': 3387,\n",
              " '##opoulos': 13791,\n",
              " 'julian': 9328,\n",
              " 'denis': 7559,\n",
              " '25th': 16711,\n",
              " 'ind': 1092,\n",
              " 'fable': 10221,\n",
              " 'gut': 3648,\n",
              " '##uel': 2111,\n",
              " 'pierce': 5704,\n",
              " 'neglected': 9307,\n",
              " 'disconcerting': 13693,\n",
              " 'scaring': 16342,\n",
              " 'historian': 10742,\n",
              " '##enbart': 11692,\n",
              " 'speci': 5937,\n",
              " 'luckily': 10723,\n",
              " 'cartoon': 1412,\n",
              " '##arron': 16199,\n",
              " 'lucas': 7633,\n",
              " '##usion': 4732,\n",
              " 'origi': 8108,\n",
              " 'wig': 11531,\n",
              " 'ludicrous': 7055,\n",
              " 'photogra': 16407,\n",
              " 'ruggero': 13703,\n",
              " 'tut': 7175,\n",
              " '##mas': 1729,\n",
              " 'heartening': 15952,\n",
              " 'durb': 9766,\n",
              " 'hes': 6601,\n",
              " 'conrack': 12020,\n",
              " 'polly': 15836,\n",
              " '##room': 5929,\n",
              " 'sunrise': 10691,\n",
              " 'clifford': 17240,\n",
              " '##ator': 2912,\n",
              " 'seal': 14606,\n",
              " 'iconic': 9479,\n",
              " 'dwarf': 18062,\n",
              " 'albeit': 7745,\n",
              " 'octopus': 11272,\n",
              " 'television': 1457,\n",
              " 'masterly': 15662,\n",
              " 'industry': 5123,\n",
              " 'georget': 17651,\n",
              " 'famed': 15434,\n",
              " 'claus': 10255,\n",
              " 'flying': 7629,\n",
              " 'spots': 8890,\n",
              " 'plenty': 3383,\n",
              " 'enchanted': 7703,\n",
              " 'schwarzenegger': 18047,\n",
              " 'december': 6523,\n",
              " 'conclud': 10928,\n",
              " '##thy': 11893,\n",
              " 'toget': 2114,\n",
              " '##way': 1698,\n",
              " 'argu': 2998,\n",
              " 'scream': 3608,\n",
              " 'engross': 6864,\n",
              " '##ison': 1901,\n",
              " '##opted': 10134,\n",
              " '##me': 1898,\n",
              " 'friendship': 6346,\n",
              " 'lawyer': 8334,\n",
              " 'attor': 9058,\n",
              " 'textbook': 13296,\n",
              " 'vid': 5790,\n",
              " 'blocks': 16474,\n",
              " 'donna': 15057,\n",
              " 'devil': 3054,\n",
              " 'sleeve': 16907,\n",
              " 'ruth': 4907,\n",
              " 'throughly': 15520,\n",
              " 'truff': 12014,\n",
              " 'revelation': 11108,\n",
              " 'ahista': 16378,\n",
              " '##aaaa': 6033,\n",
              " 'brass': 10049,\n",
              " 'tud': 14123,\n",
              " 'apologize': 8547,\n",
              " 'watchin': 4503,\n",
              " 'patience': 10682,\n",
              " 'dumbland': 16222,\n",
              " '\"': 6,\n",
              " '##ane': 863,\n",
              " '##yers': 11590,\n",
              " 'which': 635,\n",
              " '##um': 377,\n",
              " '##for': 702,\n",
              " 'reba': 10014,\n",
              " 'fights': 12891,\n",
              " 'arrival': 10867,\n",
              " 'wagon': 13340,\n",
              " '##wal': 3900,\n",
              " 'both': 1252,\n",
              " '22': 5739,\n",
              " 'spends': 8349,\n",
              " '##enster': 14431,\n",
              " 'hay': 3101,\n",
              " '##idy': 6719,\n",
              " 'phrase': 8157,\n",
              " 'howeve': 15085,\n",
              " 'funky': 12138,\n",
              " '##inkle': 8939,\n",
              " '##ric': 2967,\n",
              " '##ova': 16338,\n",
              " '##ro': 721,\n",
              " 'trashed': 12800,\n",
              " 'lizzie': 13672,\n",
              " 'cer': 1033,\n",
              " 'revisionist': 11053,\n",
              " 'iam': 13980,\n",
              " 'lucky': 2252,\n",
              " '##itch': 1822,\n",
              " 'affair': 6487,\n",
              " 'wont': 11536,\n",
              " 'mcgo': 16293,\n",
              " 'affinity': 16791,\n",
              " 'those': 508,\n",
              " 'rapid': 13135,\n",
              " 'grandma': 16519,\n",
              " 'fear': 2962,\n",
              " 'admire': 5286,\n",
              " 'relent': 10549,\n",
              " 'par': 951,\n",
              " 'skept': 6993,\n",
              " 'bros': 4170,\n",
              " '##wind': 14331,\n",
              " '##atus': 14420,\n",
              " '##irt': 14632,\n",
              " 'helped': 12739,\n",
              " 'basek': 7392,\n",
              " 'lee': 2096,\n",
              " 'snare': 12556,\n",
              " 'kohut': 17225,\n",
              " '##ately': 1271,\n",
              " 'between': 1497,\n",
              " 'dance': 3877,\n",
              " 'unhinged': 7777,\n",
              " 'trif': 12613,\n",
              " 'mates': 9128,\n",
              " 'burles': 16031,\n",
              " 'conspir': 6840,\n",
              " 'screenwriters': 17063,\n",
              " 'aid': 9741,\n",
              " 'switching': 17655,\n",
              " 'incomprehensible': 9653,\n",
              " 'woronov': 14795,\n",
              " 'sisters': 4282,\n",
              " 'violent': 3341,\n",
              " 'gwyn': 11102,\n",
              " 'perfo': 7376,\n",
              " 'frid': 10083,\n",
              " 'california': 9552,\n",
              " 'rom': 862,\n",
              " 'nail': 6615,\n",
              " 'offbeat': 9671,\n",
              " 'lumiere': 13282,\n",
              " 'belo': 5572,\n",
              " 'listings': 15936,\n",
              " 'hiking': 12217,\n",
              " 'breatht': 7659,\n",
              " 'carter': 6328,\n",
              " 'blonder': 17159,\n",
              " '##mu': 14293,\n",
              " 'widowed': 11027,\n",
              " 'pier': 3659,\n",
              " 'pink': 4476,\n",
              " 'disclos': 16636,\n",
              " 'fluke': 17204,\n",
              " 'villains': 10876,\n",
              " 'lone': 3274,\n",
              " 'minnesota': 11322,\n",
              " 'cla': 5258,\n",
              " 'leaves': 5363,\n",
              " 'ii': 1872,\n",
              " 'profession': 16558,\n",
              " 'fort': 2571,\n",
              " 'crooks': 17757,\n",
              " 'thames': 14392,\n",
              " '##erce': 8792,\n",
              " 'hitler': 5300,\n",
              " 'earns': 15447,\n",
              " 'awesome': 1747,\n",
              " 'ended': 3321,\n",
              " 'trust': 6758,\n",
              " 'adap': 8941,\n",
              " 'dough': 13899,\n",
              " 'yarn': 9869,\n",
              " '##andering': 8023,\n",
              " '##esp': 10023,\n",
              " 'extrem': 1155,\n",
              " 'lengthy': 10859,\n",
              " 'knowledge': 4723,\n",
              " 'elegant': 7064,\n",
              " 'kicking': 10842,\n",
              " 'animated': 2008,\n",
              " '##arter': 6221,\n",
              " 'prais': 16545,\n",
              " 'fictio': 17386,\n",
              " '##ober': 5795,\n",
              " 'chopper': 17047,\n",
              " 'ful': 2106,\n",
              " 'choppy': 13213,\n",
              " 'coons': 12225,\n",
              " 'nickelodeon': 9682,\n",
              " 'pasolini': 18292,\n",
              " '##strasse': 10686,\n",
              " '##rat': 11567,\n",
              " 'podge': 8700,\n",
              " 'dialo': 12815,\n",
              " 'fistful': 17697,\n",
              " 'arguably': 3863,\n",
              " 'darkly': 15681,\n",
              " 'stumble': 6242,\n",
              " 'saturd': 16374,\n",
              " 'marshall': 9565,\n",
              " 'enormously': 11086,\n",
              " 'romania': 7624,\n",
              " 'effective': 5652,\n",
              " 'shipment': 17016,\n",
              " 'jones': 3171,\n",
              " 'amateurish': 6072,\n",
              " '##dish': 14252,\n",
              " 'gho': 12753,\n",
              " '##eretta': 13596,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIID_rquXa37",
        "outputId": "fa56e763-0595-45d1-b604-19ede965e957"
      },
      "source": [
        "!mkdir tokenizer\n",
        "bert_wordpiece_tokenizer.save_model(\"tokenizer\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tokenizer/vocab.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF5_gklbXeeu"
      },
      "source": [
        "tokenizer = BertWordPieceTokenizer.from_file(\"tokenizer/vocab.txt\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaKwOs23boQh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-ANSWWKXz29"
      },
      "source": [
        "tokenized_sentence = tokenizer.encode(\"Oh it works just fine\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hC11u5e-X35m",
        "outputId": "84068484-3492-4433-a2ad-2f58704d1000"
      },
      "source": [
        "tokenized_sentence.tokens"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]', 'oh', 'it', 'works', 'just', 'fine', '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f5gF5m4X5m9"
      },
      "source": [
        "tokenized_sentence = tokenizer.encode(\"ohoh i thougt it might be workingg well\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7-Nt9n2YA8E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c36134e-acf7-4788-c8d5-80a25419143f"
      },
      "source": [
        "from transformers import BertTokenizerFast \n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"tokenizer\") "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "file tokenizer/config.json not found\n",
            "file tokenizer/config.json not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHwTfLvKYGKA",
        "outputId": "dbcad4ab-e74f-4894-cb15-bed974a672f3"
      },
      "source": [
        "from transformers import LineByLineTextDataset \n",
        "dataset = LineByLineTextDataset(tokenizer=tokenizer, file_path=\"corpus.txt\", block_size=128) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:124: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njU0BD1UYMVE"
      },
      "source": [
        "from transformers import DataCollatorForLanguageModeling \n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.15) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBM3SvrHYTNH"
      },
      "source": [
        "from transformers import TrainingArguments \n",
        "training_args = TrainingArguments(output_dir=\"BERT\", overwrite_output_dir=True, num_train_epochs=1, per_device_train_batch_size=128) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_u5_N_-9YYqw"
      },
      "source": [
        "from transformers import BertConfig, BertForMaskedLM \n",
        "bert = BertForMaskedLM(BertConfig()) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQY0-ZLvYYtm"
      },
      "source": [
        "from transformers import Trainer \n",
        "trainer = Trainer(model=bert, args=training_args, data_collator=data_collator, train_dataset=dataset) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "bVZDxhXBYYym",
        "outputId": "bfcb2ab4-7cbd-4e76-d6d7-673263d56d6a"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 50022\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 128\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 391\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='391' max='391' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [391/391 04:42, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=391, training_loss=5.378278727421675, metrics={'train_runtime': 283.7543, 'train_samples_per_second': 176.286, 'train_steps_per_second': 1.378, 'total_flos': 812585139730200.0, 'train_loss': 5.378278727421675, 'epoch': 1.0})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uzttHnJYY1C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50607221-359b-4601-f3b4-04004181a2a7"
      },
      "source": [
        "trainer.save_model(\"MyBERT\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to MyBERT\n",
            "Configuration saved in MyBERT/config.json\n",
            "Model weights saved in MyBERT/pytorch_model.bin\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-j4LqJHYs0F",
        "outputId": "6b8098f5-338c-4b27-b06a-762272a5120b"
      },
      "source": [
        "from transformers import BertConfig \n",
        "BertConfig() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertConfig {\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"gradient_checkpointing\": false,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"layer_norm_eps\": 1e-12,\n",
              "  \"max_position_embeddings\": 512,\n",
              "  \"model_type\": \"bert\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"transformers_version\": \"4.8.2\",\n",
              "  \"type_vocab_size\": 2,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 30522\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyY0_v-eYs2k",
        "outputId": "df0a4444-a558-4896-d0b0-39b97c103646"
      },
      "source": [
        "tiny_bert_config = BertConfig(max_position_embeddings=512, hidden_size=128, num_attention_heads=2, num_hidden_layers=2, intermediate_size=512) \n",
        "tiny_bert_config "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertConfig {\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"gradient_checkpointing\": false,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 128,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 512,\n",
              "  \"layer_norm_eps\": 1e-12,\n",
              "  \"max_position_embeddings\": 512,\n",
              "  \"model_type\": \"bert\",\n",
              "  \"num_attention_heads\": 2,\n",
              "  \"num_hidden_layers\": 2,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"transformers_version\": \"4.8.2\",\n",
              "  \"type_vocab_size\": 2,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 30522\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "ByC2zBtwYs44",
        "outputId": "fede53a9-694d-4fde-f256-3c98780b9b9c"
      },
      "source": [
        "tiny_bert = BertForMaskedLM(tiny_bert_config) \n",
        "trainer = Trainer(model=tiny_bert, args=training_args, data_collator=data_collator, train_dataset=dataset) \n",
        "trainer.train() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 50022\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 128\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 391\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='391' max='391' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [391/391 00:21, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=391, training_loss=8.895718235493925, metrics={'train_runtime': 21.5776, 'train_samples_per_second': 2318.234, 'train_steps_per_second': 18.121, 'total_flos': 32771457490200.0, 'train_loss': 8.895718235493925, 'epoch': 1.0})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5661f9afceac41cd81911ec61f840d1c",
            "0fe97a5a63614b35b1a58cb8d9765242",
            "6295bed1bbfc43ff8bd374152775b094",
            "91e3626b49814c7e85fc351d6cea403c",
            "cd7b13f0ba0f44a88b1d085fb5acf789",
            "24e111b1fc5746a8a69f862a0dc3bc7d",
            "e345fb951df24e0d848a051a485b4b65",
            "86b7927b6dc44fb28cf3b006163c39cf",
            "133035cbbade4827bc6764218387a54b",
            "e4efd2d54399463db446591d18cbe6fd",
            "c1e03b6d025a4dba9e37eb35c48d93ec",
            "62399066111345ec827e1912ec1d97ba",
            "73ca0820cf8a482bb3cb4bd658e7a5d3",
            "2989c05594ea4054b311517ce5339ed2",
            "ef71247bb53a4c709d59e63ab7d60c33",
            "62b92d97fdcb49b1ade6d076d0b203eb",
            "94a9c2fcf79f4ac0a8f2d712411f7d2b",
            "d8e8c28122024aadb70ff1aab5530eeb",
            "7a9083129f274149a176a0e31eb48411",
            "dac236c954ef4b0f99067b8bbeba6283",
            "96ad3e5ee6bc4398a0c6e8ea948682a4",
            "3f2e7ff1d0ad466196075aad10b8b84a",
            "9fb9172e15b3405fab9a7db14d0c560d",
            "48f55d9d4e3046d5abe21fef5b2a377c",
            "7d102900f8884e44aa4953d89ad79465",
            "6946d2105b2e4fd1bfab2b10f1256053",
            "0b351be38ce9450eb4f4a857132b0a79",
            "c41a59274c78422fa1c846a1711b2439",
            "477900896cec431f98ed705f5fbbf78b",
            "6cead6beda334e7a8db3f27ad5845705",
            "d26b4d4dbcd243cd8933f81fffad0b4d",
            "a0d2c4f1560a4a6bab0be1285c932283",
            "9dac89e1bf484a1fafaa1b5235846d93",
            "2290a421c99944a19da4fa1888204a0a",
            "3fe4f71880a5497e950d15a381614651",
            "7fc1dee184a54de987dbba3af55c597e",
            "4e9a142be38247088fe4f3a7d6ecd6f3",
            "127e05f39b2d4b0f84dd7ca57d71cc98",
            "73de1777b2f5478891fc9b8dc46c26a0",
            "476bdde5624144919c7abb27938c7221"
          ]
        },
        "id": "fMCmbDfFYs_s",
        "outputId": "b8f7f093-cc44-465f-d412-5a38025c9f20"
      },
      "source": [
        "from transformers import TFBertModel, BertTokenizerFast \n",
        "bert = TFBertModel.from_pretrained(\"bert-base-uncased\") \n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\") \n",
        "bert.layers "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://huggingface.co/bert-base-uncased/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp_jskfvy4\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5661f9afceac41cd81911ec61f840d1c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/bert-base-uncased/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "creating metadata file for /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.8.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp574a63hw\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "133035cbbade4827bc6764218387a54b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=536063208.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 in cache at /root/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5\n",
            "creating metadata file for /root/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5\n",
            "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /root/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmptjrcqhtk\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94a9c2fcf79f4ac0a8f2d712411f7d2b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "creating metadata file for /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp83epubcm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d102900f8884e44aa4953d89ad79465",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "creating metadata file for /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpgk2_ycuj\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9dac89e1bf484a1fafaa1b5235846d93",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "creating metadata file for /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<transformers.models.bert.modeling_tf_bert.TFBertMainLayer at 0x7f5b9fd316d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-tQO7EbYtCR",
        "outputId": "5390c3db-44ea-437f-e812-354840dcbfa1"
      },
      "source": [
        "tokenized_text = tokenizer.batch_encode_plus([\"hello how is it going with you\",\"lets test it\"], return_tensors=\"tf\", max_length=256, truncation=True, pad_to_max_length=True) \n",
        "bert(tokenized_text) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TFBaseModelOutputWithPooling([('last_hidden_state',\n",
              "                               <tf.Tensor: shape=(2, 256, 768), dtype=float32, numpy=\n",
              "                               array([[[ 1.00471288e-01,  6.77022934e-02, -8.33591744e-02, ...,\n",
              "                                        -4.93304461e-01,  1.16539642e-01,  2.26646975e-01],\n",
              "                                       [ 3.23624432e-01,  3.70718002e-01,  6.14686370e-01, ...,\n",
              "                                        -6.27267480e-01,  3.79082561e-01,  7.05312043e-02],\n",
              "                                       [ 1.99534193e-01, -8.75509918e-01, -6.47860616e-02, ...,\n",
              "                                        -1.28080100e-02,  3.07651967e-01, -2.07310896e-02],\n",
              "                                       ...,\n",
              "                                       [-6.53299540e-02,  1.19045913e-01,  5.76846719e-01, ...,\n",
              "                                        -2.95459926e-01,  2.49742977e-02,  1.13964222e-01],\n",
              "                                       [-2.64715403e-01, -7.86383227e-02,  5.47281384e-01, ...,\n",
              "                                        -1.37515306e-01, -5.94685934e-02, -5.17925322e-02],\n",
              "                                       [-2.44959027e-01, -1.14799343e-01,  5.92174053e-01, ...,\n",
              "                                        -1.56881928e-01, -3.39758471e-02, -8.46135020e-02]],\n",
              "                               \n",
              "                                      [[ 2.94565968e-02,  2.30868325e-01,  2.92651832e-01, ...,\n",
              "                                        -1.30421251e-01,  1.89659148e-01,  4.68428344e-01],\n",
              "                                       [ 1.70523262e+00,  6.91359818e-01,  7.31509924e-01, ...,\n",
              "                                         2.89304137e-01,  5.36758423e-01, -1.54552370e-01],\n",
              "                                       [ 1.04597911e-01,  9.63677615e-02,  6.99652955e-02, ...,\n",
              "                                        -4.15922850e-01, -1.18989676e-01, -6.72240913e-01],\n",
              "                                       ...,\n",
              "                                       [ 8.00909936e-01,  2.38983527e-01,  4.15492773e-01, ...,\n",
              "                                         3.90535370e-02,  2.34373271e-01,  1.22278899e-01],\n",
              "                                       [ 2.60863423e-01,  4.43267561e-02,  3.63649219e-01, ...,\n",
              "                                        -7.53857195e-04,  3.84623855e-02, -2.14213550e-01],\n",
              "                                       [-2.30111465e-01, -4.98387933e-01, -1.26490444e-02, ...,\n",
              "                                         4.49868321e-01,  6.16021976e-02, -2.61357427e-01]]],\n",
              "                                     dtype=float32)>),\n",
              "                              ('pooler_output',\n",
              "                               <tf.Tensor: shape=(2, 768), dtype=float32, numpy=\n",
              "                               array([[-0.9204854 , -0.37138984, -0.6051261 , ..., -0.4473696 ,\n",
              "                                       -0.6434759 ,  0.9423271 ],\n",
              "                                      [-0.88541585, -0.26547667,  0.21014938, ...,  0.17237104,\n",
              "                                       -0.640299  ,  0.88883436]], dtype=float32)>)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMmRg2X-Y7LF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a4edc0c-0d1a-4033-c44a-5476e5ea0914"
      },
      "source": [
        "from tensorflow import keras \n",
        "import tensorflow as tf \n",
        "max_length = 256 \n",
        "tokens = keras.layers.Input(shape=(max_length,), dtype=tf.dtypes.int32) \n",
        "masks = keras.layers.Input(shape=(max_length,), dtype=tf.dtypes.int32) \n",
        "embedding_layer = bert.layers[0]([tokens,masks])[0][:,0,:] \n",
        "dense = tf.keras.layers.Dense(units=2, activation=\"softmax\")(embedding_layer) \n",
        "model = keras.Model([tokens,masks],dense) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8xeS5TyY7No",
        "outputId": "34427854-5ba6-41e2-ec99-88b82ec59505"
      },
      "source": [
        "tokenized = tokenizer.batch_encode_plus([\"hello how is it going with you\",\"hello how is it going with you\"], return_tensors=\"tf\", max_length= max_length, truncation=True, pad_to_max_length=True) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGMwpG8OY7P_",
        "outputId": "fd5fdad8-8545-418e-9a4b-378c3a79e934"
      },
      "source": [
        "model([tokenized[\"input_ids\"],tokenized[\"attention_mask\"]]) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[0.56051165, 0.43948835],\n",
              "       [0.56051165, 0.43948835]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b24ahO1UY7SR",
        "outputId": "41ea32ad-1ad7-4a2b-d525-446ca88f4cbb"
      },
      "source": [
        "model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]) \n",
        "model.summary() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bert (TFBertMainLayer)          TFBaseModelOutputWit 109482240   input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem (Slici (None, 768)          0           bert[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 2)            1538        tf.__operators__.getitem[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 109,483,778\n",
            "Trainable params: 109,483,778\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSCi31iUZL1Y"
      },
      "source": [
        "model.layers[2].trainable = False "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcfBTBw8ZL6V",
        "outputId": "08436178-6e86-4151-f483-2c2671ef7cb0"
      },
      "source": [
        "import pandas as pd \n",
        "imdb_df = pd.read_csv(\"IMDB Dataset.csv\") \n",
        "reviews = list(imdb_df.review) \n",
        "tokenized_reviews = tokenizer.batch_encode_plus(reviews, return_tensors=\"tf\", max_length=max_length, truncation=True, pad_to_max_length=True) \n",
        "\n",
        "import numpy as np \n",
        "train_split = int(0.8 * len(tokenized_reviews[\"attention_mask\"])) \n",
        "train_tokens = tokenized_reviews[\"input_ids\"][:train_split] \n",
        "test_tokens = tokenized_reviews[\"input_ids\"][train_split:] \n",
        "train_masks = tokenized_reviews[\"attention_mask\"][:train_split] \n",
        "test_masks = tokenized_reviews[\"attention_mask\"][train_split:] \n",
        "sentiments = list(imdb_df.sentiment) \n",
        "labels = np.array([[0,1] if sentiment == \"positive\" else [1,0] for sentiment in sentiments]) \n",
        "train_labels = labels[:train_split] \n",
        "test_labels = labels[train_split:] "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaQlIkdZZL8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faaa116b-6cc2-4263-876c-bebf162eafe6"
      },
      "source": [
        "model.fit([train_tokens,train_masks],train_labels, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RTyDkLzZL-8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}